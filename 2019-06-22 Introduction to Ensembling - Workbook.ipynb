{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "description of dataset [here](https://scikit-learn.org/stable/datasets/index.html#diabetes-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'age',\n",
    "    'sex',\n",
    "    'body_mass_index',\n",
    "    'average_blood_pressure',\n",
    "    's1',\n",
    "    's2',\n",
    "    's3',\n",
    "    's4',\n",
    "    's5',\n",
    "    's6'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset['data']\n",
    "y = dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>body_mass_index</th>\n",
       "      <th>average_blood_pressure</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-3.639623e-16</td>\n",
       "      <td>1.309912e-16</td>\n",
       "      <td>-8.013951e-16</td>\n",
       "      <td>1.289818e-16</td>\n",
       "      <td>-9.042540e-17</td>\n",
       "      <td>1.301121e-16</td>\n",
       "      <td>-4.563971e-16</td>\n",
       "      <td>3.863174e-16</td>\n",
       "      <td>-3.848103e-16</td>\n",
       "      <td>-3.398488e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.072256e-01</td>\n",
       "      <td>-4.464164e-02</td>\n",
       "      <td>-9.027530e-02</td>\n",
       "      <td>-1.123996e-01</td>\n",
       "      <td>-1.267807e-01</td>\n",
       "      <td>-1.156131e-01</td>\n",
       "      <td>-1.023071e-01</td>\n",
       "      <td>-7.639450e-02</td>\n",
       "      <td>-1.260974e-01</td>\n",
       "      <td>-1.377672e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.729927e-02</td>\n",
       "      <td>-4.464164e-02</td>\n",
       "      <td>-3.422907e-02</td>\n",
       "      <td>-3.665645e-02</td>\n",
       "      <td>-3.424784e-02</td>\n",
       "      <td>-3.035840e-02</td>\n",
       "      <td>-3.511716e-02</td>\n",
       "      <td>-3.949338e-02</td>\n",
       "      <td>-3.324879e-02</td>\n",
       "      <td>-3.317903e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.383060e-03</td>\n",
       "      <td>-4.464164e-02</td>\n",
       "      <td>-7.283766e-03</td>\n",
       "      <td>-5.670611e-03</td>\n",
       "      <td>-4.320866e-03</td>\n",
       "      <td>-3.819065e-03</td>\n",
       "      <td>-6.584468e-03</td>\n",
       "      <td>-2.592262e-03</td>\n",
       "      <td>-1.947634e-03</td>\n",
       "      <td>-1.077698e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.807591e-02</td>\n",
       "      <td>5.068012e-02</td>\n",
       "      <td>3.124802e-02</td>\n",
       "      <td>3.564384e-02</td>\n",
       "      <td>2.835801e-02</td>\n",
       "      <td>2.984439e-02</td>\n",
       "      <td>2.931150e-02</td>\n",
       "      <td>3.430886e-02</td>\n",
       "      <td>3.243323e-02</td>\n",
       "      <td>2.791705e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.107267e-01</td>\n",
       "      <td>5.068012e-02</td>\n",
       "      <td>1.705552e-01</td>\n",
       "      <td>1.320442e-01</td>\n",
       "      <td>1.539137e-01</td>\n",
       "      <td>1.987880e-01</td>\n",
       "      <td>1.811791e-01</td>\n",
       "      <td>1.852344e-01</td>\n",
       "      <td>1.335990e-01</td>\n",
       "      <td>1.356118e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age           sex  body_mass_index  average_blood_pressure  \\\n",
       "count  4.420000e+02  4.420000e+02     4.420000e+02            4.420000e+02   \n",
       "mean  -3.639623e-16  1.309912e-16    -8.013951e-16            1.289818e-16   \n",
       "std    4.761905e-02  4.761905e-02     4.761905e-02            4.761905e-02   \n",
       "min   -1.072256e-01 -4.464164e-02    -9.027530e-02           -1.123996e-01   \n",
       "25%   -3.729927e-02 -4.464164e-02    -3.422907e-02           -3.665645e-02   \n",
       "50%    5.383060e-03 -4.464164e-02    -7.283766e-03           -5.670611e-03   \n",
       "75%    3.807591e-02  5.068012e-02     3.124802e-02            3.564384e-02   \n",
       "max    1.107267e-01  5.068012e-02     1.705552e-01            1.320442e-01   \n",
       "\n",
       "                 s1            s2            s3            s4            s5  \\\n",
       "count  4.420000e+02  4.420000e+02  4.420000e+02  4.420000e+02  4.420000e+02   \n",
       "mean  -9.042540e-17  1.301121e-16 -4.563971e-16  3.863174e-16 -3.848103e-16   \n",
       "std    4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02   \n",
       "min   -1.267807e-01 -1.156131e-01 -1.023071e-01 -7.639450e-02 -1.260974e-01   \n",
       "25%   -3.424784e-02 -3.035840e-02 -3.511716e-02 -3.949338e-02 -3.324879e-02   \n",
       "50%   -4.320866e-03 -3.819065e-03 -6.584468e-03 -2.592262e-03 -1.947634e-03   \n",
       "75%    2.835801e-02  2.984439e-02  2.931150e-02  3.430886e-02  3.243323e-02   \n",
       "max    1.539137e-01  1.987880e-01  1.811791e-01  1.852344e-01  1.335990e-01   \n",
       "\n",
       "                 s6  \n",
       "count  4.420000e+02  \n",
       "mean  -3.398488e-16  \n",
       "std    4.761905e-02  \n",
       "min   -1.377672e-01  \n",
       "25%   -3.317903e-02  \n",
       "50%   -1.077698e-03  \n",
       "75%    2.791705e-02  \n",
       "max    1.356118e-01  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x = pd.DataFrame(X, columns=columns)\n",
    "df_x.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving Normally\n",
    "\n",
    "Cross Validating. \n",
    "We will use `KFold` class to split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_hat):\n",
    "    # TODO implement rmse\n",
    "    return np.sqrt(mean_squared_error(y_true, y_hat))\n",
    "\n",
    "def print_all_metrics(y_true, y_hat, type='train'):\n",
    "    print('''\n",
    "    ....{} metrics....\n",
    "    rmse: {:.2f}\n",
    "    mae: {:.2f},\n",
    "    r2: {:.2f}\n",
    "    '''.format(\n",
    "        type,\n",
    "        rmse(y_true, y_hat),\n",
    "        mean_absolute_error(y_true, y_hat),\n",
    "        r2_score(y_true, y_hat)\n",
    "    ))\n",
    "    \n",
    "def all_metrics(y_true, y_hat):\n",
    "    return (\n",
    "        rmse(y_true, y_hat),\n",
    "        mean_absolute_error(y_true, y_hat),\n",
    "        r2_score(y_true, y_hat) \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 142\n",
    "folds = KFold(5, shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cv(folds, mdl, X, y):\n",
    "    cv_metrics = list()\n",
    "    # TODO impl\n",
    "    \n",
    "    for cv_idx, (train_index, test_index) in enumerate(folds.split(X)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        m = mdl.fit(X_train, y_train)\n",
    "        y_pred = m.predict(X_test)\n",
    "        _rmse, _mae, _r2 = all_metrics(y_test, y_pred)\n",
    "        \n",
    "        cv_metrics.append([cv_idx, _rmse, _mae, _r2])\n",
    "        \n",
    "    return pd.DataFrame(cv_metrics, columns=['cv_idx', 'rmse', 'mae', 'r2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_idx</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>47.452700</td>\n",
       "      <td>38.011039</td>\n",
       "      <td>0.512996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>54.830096</td>\n",
       "      <td>43.961871</td>\n",
       "      <td>0.515797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>56.735936</td>\n",
       "      <td>46.679995</td>\n",
       "      <td>0.430081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>56.915700</td>\n",
       "      <td>47.203529</td>\n",
       "      <td>0.495173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>56.144112</td>\n",
       "      <td>45.848717</td>\n",
       "      <td>0.507949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cv_idx       rmse        mae        r2\n",
       "0       0  47.452700  38.011039  0.512996\n",
       "1       1  54.830096  43.961871  0.515797\n",
       "2       2  56.735936  46.679995  0.430081\n",
       "3       3  56.915700  47.203529  0.495173\n",
       "4       4  56.144112  45.848717  0.507949"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_metrics = do_cv(folds, LinearRegression(), X, y)\n",
    "\n",
    "cv_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging:  Bootstrap Aggregating\n",
    "\n",
    "## Main Idea\n",
    "\n",
    "Bagging could be done by simply **train several weak predictor and take the average of each predictors**.\n",
    "\n",
    "Bagging comes from name: *Bootstrap Aggregating*. Bootstraping in statistics is an estimation of sampling distribution by taking random samples with replacement$^{5}$. Bagging predictor uses *bootstrap* because it literally train on different algorithm with same data${^6}$, thus it is sampling with replacement / bootstraping.\n",
    "\n",
    "\n",
    "> A critical factor in whether bagging will improve accuracy is the stability of the procedure for constructing $\\varphi$. If changes in $\\mathcal{L}$  i.e. a replicate $\\mathcal{L}$, produces small changes in $\\varphi$, then $\\varphi_B$ will be close to $\\varphi$. Improvement will occur for unstable procedures where a small change in $\\mathcal{L}$ can result in large changes in $\\varphi$ $^6$\n",
    "\n",
    "where:\n",
    "\n",
    "- $\\mathcal{L}$ is the learning sets / training set / training data\n",
    "- $\\varphi$ is the predictor\n",
    "- $\\varphi_B$ is the predictor trained on bootstrap sample of data\n",
    "\n",
    "\n",
    "\n",
    "What does it means? It means that Bagging will excel if there is a small change in training set $\\mathcal{L}$, results in big big change in prediction of $\\varphi$.\n",
    "\n",
    "\n",
    "## What Algorithms Could be Combined by Bagging?\n",
    "\n",
    "> neural nets, classification and regression trees, and subset selection\n",
    "\n",
    "\n",
    "## Toy Regressors\n",
    "\n",
    "For this purpose we will use 3 toy regressors: `LinearRegression`, `Lasso`, and `Ridge` \n",
    "\n",
    "$$\n",
    "f(x) =  \\sum_{m=0}^{M} \\frac{1}{M} * h_m(x)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $m$ is the model index\n",
    "\n",
    "- $h(x)$ is the prediction for model $h_m$ given the input $x$\n",
    "\n",
    "- $f(x)$ is the final prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Bagging Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBaggingModel(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, base_estimator, n_iter, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        self.models = [base_estimator] * n_iter # TODO\n",
    "        self.len_models = len(self.models)\n",
    "        \n",
    "        self.model_weights = [1. / n_iter for i in range(n_iter)] # TODO\n",
    "    \n",
    "    def _get_random_choice(self, X, y):\n",
    "        # TODO \n",
    "        idxs = np.random.choice(np.arange(X.shape[0]), X.shape[0])\n",
    "        X_choice = X[idxs]\n",
    "        y_choice = y[idxs]\n",
    "        return X_choice, y_choice\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # TODO \n",
    "        for i in range(self.len_models):\n",
    "            X_train, y_train = self._get_random_choice(X, y)\n",
    "            self.models[i].fit(X_train, y_train) ## can be simplified to self.models[i].fit(*self._get_random_choice(X, y))\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = list()\n",
    "        # TODO \n",
    "        \n",
    "        for i in range(self.len_models):\n",
    "            y_pred = self.models[i].predict(X)\n",
    "            predictions.append(y_pred)\n",
    "        \n",
    "        return np.sum(\n",
    "            (np.array(predictions).T * self.model_weights).T,\n",
    "            axis=0\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_idx</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>49.827066</td>\n",
       "      <td>40.499336</td>\n",
       "      <td>0.463041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>54.359228</td>\n",
       "      <td>42.743706</td>\n",
       "      <td>0.524078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>57.711236</td>\n",
       "      <td>47.095899</td>\n",
       "      <td>0.410318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>56.865259</td>\n",
       "      <td>46.960065</td>\n",
       "      <td>0.496067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>55.425224</td>\n",
       "      <td>45.305436</td>\n",
       "      <td>0.520469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cv_idx       rmse        mae        r2\n",
       "0       0  49.827066  40.499336  0.463041\n",
       "1       1  54.359228  42.743706  0.524078\n",
       "2       2  57.711236  47.095899  0.410318\n",
       "3       3  56.865259  46.960065  0.496067\n",
       "4       4  55.425224  45.305436  0.520469"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_cv(folds, SimpleBaggingModel(LinearRegression(), 10), X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Using Sklearn\n",
    "\n",
    "Sklearn has a nice wrapper for simple bagging, both classifier and regressor. It resides at `sklearn.ensemble` module, `BaggingClassifier`, `BaggingRegressor`, `VotingClassifier` and `VotingRegressor`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor, BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_idx</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>48.497070</td>\n",
       "      <td>39.111117</td>\n",
       "      <td>0.491324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>54.933590</td>\n",
       "      <td>44.000295</td>\n",
       "      <td>0.513967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>56.873263</td>\n",
       "      <td>46.557978</td>\n",
       "      <td>0.427318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>56.897640</td>\n",
       "      <td>47.119511</td>\n",
       "      <td>0.495493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>56.379280</td>\n",
       "      <td>45.924513</td>\n",
       "      <td>0.503819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cv_idx       rmse        mae        r2\n",
       "0       0  48.497070  39.111117  0.491324\n",
       "1       1  54.933590  44.000295  0.513967\n",
       "2       2  56.873263  46.557978  0.427318\n",
       "3       3  56.897640  47.119511  0.495493\n",
       "4       4  56.379280  45.924513  0.503819"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: do_cv with BaggingRegressor, base_estimator = LinearRegression\n",
    "do_cv(folds, BaggingRegressor(base_estimator=LinearRegression()), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_idx</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>48.217676</td>\n",
       "      <td>38.881483</td>\n",
       "      <td>0.497168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>58.479110</td>\n",
       "      <td>49.415773</td>\n",
       "      <td>0.449204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>59.139107</td>\n",
       "      <td>50.065281</td>\n",
       "      <td>0.380778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>59.039757</td>\n",
       "      <td>48.936453</td>\n",
       "      <td>0.456790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>58.301086</td>\n",
       "      <td>49.801070</td>\n",
       "      <td>0.469415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cv_idx       rmse        mae        r2\n",
       "0       0  48.217676  38.881483  0.497168\n",
       "1       1  58.479110  49.415773  0.449204\n",
       "2       2  59.139107  50.065281  0.380778\n",
       "3       3  59.039757  48.936453  0.456790\n",
       "4       4  58.301086  49.801070  0.469415"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: do_cv with VotingRegressor, models: LinearRegression, Lasso, Ridge\n",
    "do_cv(folds, VotingRegressor(\n",
    "    estimators=[\n",
    "        ('linreg', LinearRegression()),\n",
    "        ('lasso', Lasso()),\n",
    "        ('ridge', Ridge())\n",
    "    ]), \n",
    "      X, \n",
    "      y\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "There are 2 types of popular boosting: AdaBoost and Gradient Boosting, where each boosting is based on decision tree.\n",
    "\n",
    "## Adaptive Boosting (AdaBoost)\n",
    "\n",
    "### Main Idea\n",
    "Main idea for Adaptive Boosting is \n",
    "> iteratively train $T$ models, for each model $t \\in T$: train the model with **weighted samples**, where samples with **less error will receive less weight** in next iteration. Then combine the prediction of each model $t$ with **weighted estimators**.\n",
    "\n",
    "### Deeper Understanding: the Algorithm\n",
    "Algorithm for AdaBoost is given by $^{1, 2}$, and simple implementation could be also be found online $^{3}$. \n",
    "\n",
    "Given $(x_1, y_1) ... (x_m, y_m)$ where $x_i \\in \\mathcal{X}$, $y_i \\in \\{-1, +1\\}$\n",
    "\n",
    "Initialize: $D_1(i) = 1/m$ for $i = 1, ..., m.$ \n",
    "\n",
    "For $t = 1...T$\n",
    "\n",
    "- Train weak learner using distribution $D_t$\n",
    "- Get weak hypothesis $h_t: \\mathcal{X} -> \\{-1, +1\\}$\n",
    "- Choose $\\alpha = \\frac{1}{2} \\text{ ln } \\frac{(1 - \\epsilon_t)}{\\epsilon_t}$\n",
    "- Update, for $i \\text{ = 1, ... , m}$:\n",
    "\n",
    "$$\n",
    "D_{t+1}(i) = \\frac{D_t(i)\\text{ exp }(-\\alpha_t y_i h_t (x_i))} {Z_t}\n",
    "$$\n",
    "\n",
    "Where $Z_t$ is normalization factor. Final output:\n",
    "\n",
    "$$\n",
    "H(x) = \\text{sign}(\\sum_{t=1}^{T} \\alpha_t h_t(x))\n",
    "$$\n",
    "\n",
    "However this algorithm is for training a classifier, for regressor refer to [4]\n",
    "\n",
    "\n",
    "Notes:\n",
    "> - D = sample weight --> weight for each sample\n",
    "> - Sample in which model performs badly will be weighted more than other sample\n",
    "> - $\\alpha$ = estimator weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO define AdaBoostRegressor, n_estimators=10\n",
    "mdl = AdaBoostRegressor(base_estimator=LinearRegression(),\n",
    "                        n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_idx</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>46.680379</td>\n",
       "      <td>37.186314</td>\n",
       "      <td>0.528720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>55.343572</td>\n",
       "      <td>44.372483</td>\n",
       "      <td>0.506686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>57.396501</td>\n",
       "      <td>47.280182</td>\n",
       "      <td>0.416733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>56.732209</td>\n",
       "      <td>47.179074</td>\n",
       "      <td>0.498423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>56.775966</td>\n",
       "      <td>46.935917</td>\n",
       "      <td>0.496812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cv_idx       rmse        mae        r2\n",
       "0       0  46.680379  37.186314  0.528720\n",
       "1       1  55.343572  44.372483  0.506686\n",
       "2       2  57.396501  47.280182  0.416733\n",
       "3       3  56.732209  47.179074  0.498423\n",
       "4       4  56.775966  46.935917  0.496812"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: do_cv with AdaBoostRegressor\n",
    "do_cv(folds, mdl, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful of using Lasso or Ridge (and other regularized model) for boosting. The results might be worse, or only slightly better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cv_idx     2.000000\n",
       "rmse      61.887992\n",
       "mae       52.837713\n",
       "r2         0.344447\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparison between Lasso vs AdaBoost with Lasso as estimator\n",
    "do_cv(folds, Lasso(), X, y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cv_idx     2.000000\n",
       "rmse      60.291436\n",
       "mae       51.311308\n",
       "r2         0.377728\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_lasso = AdaBoostRegressor(base_estimator=Lasso(),\n",
    "                        n_estimators=10)\n",
    "\n",
    "do_cv(folds, mdl_lasso, X, y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting (GBM)\n",
    "\n",
    "Gradient boosting works slightly different from Adaptive Boosting. Main differences between those two algorithm are: **how to fit each iteration model** and **how to determine estimator weights for each iteration**. Idea comes from Friedman$^{9}$, and now have been improved into *extreme* gradient boosting, for example: LightGBM$^{7}$, XGBoost$^{8}$, and CatBoost$^{10}$\n",
    "\n",
    "### Main Idea\n",
    "\n",
    "Gradient boosting main idea is to train next iteration model on residual of previous model as the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO define GradientBoostingRegressor, n_estimators=10\n",
    "mdl = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation 1\n",
      "\n",
      "    ....train metrics....\n",
      "    rmse: 55.47491107519263\n",
      "    mae: 47.931418569695666,\n",
      "    r2: 0.5065771601937898\n",
      "    \n",
      "\n",
      "    ....test metrics....\n",
      "    rmse: 52.56444394990826\n",
      "    mae: 43.73903490279989,\n",
      "    r2: 0.40242178236903403\n",
      "    \n",
      "Cross Validation 2\n",
      "\n",
      "    ....train metrics....\n",
      "    rmse: 53.35330434322521\n",
      "    mae: 45.85119284616699,\n",
      "    r2: 0.5109397979959944\n",
      "    \n",
      "\n",
      "    ....test metrics....\n",
      "    rmse: 63.39114366471927\n",
      "    mae: 53.26895554133836,\n",
      "    r2: 0.3527880519487061\n",
      "    \n",
      "Cross Validation 3\n",
      "\n",
      "    ....train metrics....\n",
      "    rmse: 53.289577662852885\n",
      "    mae: 45.35429693697925,\n",
      "    r2: 0.5247353629381997\n",
      "    \n",
      "\n",
      "    ....test metrics....\n",
      "    rmse: 62.3771317980767\n",
      "    mae: 53.06529940099563,\n",
      "    r2: 0.3111134045227266\n",
      "    \n",
      "Cross Validation 4\n",
      "\n",
      "    ....train metrics....\n",
      "    rmse: 53.39010855604922\n",
      "    mae: 45.41101696828909,\n",
      "    r2: 0.5072482289524957\n",
      "    \n",
      "\n",
      "    ....test metrics....\n",
      "    rmse: 62.81946994086882\n",
      "    mae: 53.1134645599001,\n",
      "    r2: 0.38501160269023027\n",
      "    \n",
      "Cross Validation 5\n",
      "\n",
      "    ....train metrics....\n",
      "    rmse: 53.447388908885145\n",
      "    mae: 45.10348931123881,\n",
      "    r2: 0.5083456261791047\n",
      "    \n",
      "\n",
      "    ....test metrics....\n",
      "    rmse: 62.606078271113404\n",
      "    mae: 54.62348733751703,\n",
      "    r2: 0.38816481527521485\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# TODO: do_cv on GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "\n",
    "Stacking is another *Meta - Feature* learning algorithm that \"stack\" models together. \n",
    "\n",
    "## Main Idea\n",
    "Stacking works by constructing network of models. We learn to *weight* each prediction result to construct final, more accurate prediction.\n",
    "\n",
    "![stacking](https://cdn-images-1.medium.com/max/1600/0*GHYCJIjkkrP5ZgPh.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackModel(object):\n",
    "    def __init__(self, models):\n",
    "        # TODO: define models and meta_learner as linear regression\n",
    "        self.models = \n",
    "        self.meta_learner = \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        predictions = list()\n",
    "        # TODO: define \n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = list()\n",
    "        # TODO: define and return final_predictions\n",
    "        \n",
    "        return final_prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    # make pipeline for each model, containing minmaxscaler as preprocessor and the model\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.StackModel at 0x7f555007c048>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation 1\n",
      "\n",
      "    ....train metrics....\n",
      "    rmse: 27.526870386874396\n",
      "    mae: 20.95588714658343,\n",
      "    r2: 0.8785102341960441\n",
      "    \n",
      "\n",
      "    ....test metrics....\n",
      "    rmse: 62.90063010602655\n",
      "    mae: 49.449384572691606,\n",
      "    r2: 0.14430183360388305\n",
      "    \n",
      "Cross Validation 2\n",
      "\n",
      "    ....train metrics....\n",
      "    rmse: 25.420983563466706\n",
      "    mae: 19.170406795039924,\n",
      "    r2: 0.88897408044089\n",
      "    \n",
      "\n",
      "    ....test metrics....\n",
      "    rmse: 58.37330465132906\n",
      "    mae: 46.33887812408529,\n",
      "    r2: 0.4511951853681898\n",
      "    \n",
      "Cross Validation 3\n",
      "\n",
      "    ....train metrics....\n",
      "    rmse: 26.087357228349216\n",
      "    mae: 20.07656384004358,\n",
      "    r2: 0.8861033068968689\n",
      "    \n",
      "\n",
      "    ....test metrics....\n",
      "    rmse: 68.81116456051153\n",
      "    mae: 52.91720167545122,\n",
      "    r2: 0.1616705027175802\n",
      "    \n",
      "Cross Validation 4\n",
      "\n",
      "    ....train metrics....\n",
      "    rmse: 26.71528532801037\n",
      "    mae: 19.571672707095523,\n",
      "    r2: 0.8766252686460366\n",
      "    \n",
      "\n",
      "    ....test metrics....\n",
      "    rmse: 66.74097407750051\n",
      "    mae: 56.96343240600481,\n",
      "    r2: 0.30583379142640654\n",
      "    \n",
      "Cross Validation 5\n",
      "\n",
      "    ....train metrics....\n",
      "    rmse: 25.88798667067702\n",
      "    mae: 19.195143467230263,\n",
      "    r2: 0.884653751767361\n",
      "    \n",
      "\n",
      "    ....test metrics....\n",
      "    rmse: 65.07678596467794\n",
      "    mae: 51.924530867062415,\n",
      "    r2: 0.3389205760329138\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# TODO: do_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] Schapire, Robert E. [*Explaining AdaBoost*](http://rob.schapire.net/papers/explaining-adaboost.pdf). Princeton University\n",
    "\n",
    "[2] Freund, Yoav & Schapire, Robert E. [*A Short Introduction to Boosting*](https://cseweb.ucsd.edu/~yfreund/papers/IntroToBoosting.pdf). AT&T Labs\n",
    "\n",
    "[3] Sicotte, Xavier Bourret. [*Adaboost: Implementation and Intuition*](https://xavierbourretsicotte.github.io/AdaBoost.html)\n",
    "\n",
    "[4] Drucker, Harris. [*Improving Regressors using Boosting Techniques*](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.31.314&rep=rep1&type=pdf)\n",
    "\n",
    "[5] Wikipedia. [Bootstraping (Statistics)](https://en.wikipedia.org/wiki/Bootstrapping_(statistics))\n",
    "\n",
    "[6] Breiman, Leo. [*Bagging Predictors*](https://www.stat.berkeley.edu/~breiman/bagging.pdf). 1994. Technical Report No.421\n",
    "\n",
    "[7] Ke, Guolin et al. [*LightGBM: A Highly Efficient Gradient Boosting Decision Tree*](https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf). 2017. NIPS\n",
    "\n",
    "[8] Chen, Tianqi & Guestrin, Carlos. [*XGBoost: A Scalable Tree Boosting System*](https://www.kdd.org/kdd2016/papers/files/rfp0697-chenAemb.pdf). 2016. KDD\n",
    "\n",
    "[9] Friedman, Jerome H. [*Greedy Function Approximation: A Gradient Boosting Machine*](https://statweb.stanford.edu/~jhf/ftp/trebst.pdf). 1999. IMS 1999 Reitz Lecture.\n",
    "\n",
    "[10] Prokhorenkova, Liudmila et al. [*CatBoost: unbiased boosting with categorical features*](https://arxiv.org/pdf/1706.09516.pdf). 2019. ArXiv.\n",
    "\n",
    "[11] Wolpert, David H. [*Stacked Generalization*](https://www.sciencedirect.com/science/article/pii/S0893608005800231). 1992. Neural Networks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
